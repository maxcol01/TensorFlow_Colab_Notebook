{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","mount_file_id":"1NhEfdyh2b_lVQmu16AP9Oqw-lNlll-k7","authorship_tag":"ABX9TyNjydVXPSEiK/3vEV7X/a7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Transfert Learning with TensorFlow Part1: Feature extraction\n","\n","TF is leveraging an existing model architecture and learn patterns for our problem:\n","\n","- Can leverage an existing nerual network proven to work on a similar problem to our own\n","- Can leverage a working NN so we can adapt the patterns to our own data\n","- train on a smaller amount of data"],"metadata":{"id":"cKwZshpHf8YN"}},{"cell_type":"markdown","source":["## 1. Load and prepare the data"],"metadata":{"id":"3pBIvbS9A5r2"}},{"cell_type":"markdown","source":["### Load the data"],"metadata":{"id":"5ZfVqY8LA8x_"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOsUMCJVc3XS","executionInfo":{"status":"ok","timestamp":1728318395018,"user_tz":-120,"elapsed":468,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"ac3c9f9c-16fb-4173-a3e5-eaf0caacca0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Oct  7 16:26:34 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n","| N/A   46C    P8              12W /  72W |      1MiB / 23034MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["# are we using a GPU ?\n","!nvidia-smi"]},{"cell_type":"code","source":["! pip install tensorflow==2.14.0\n","import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtNYhhVwBADK","executionInfo":{"status":"ok","timestamp":1728318449253,"user_tz":-120,"elapsed":51210,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"080e3ca3-476b-46c6-c0ca-4461831c5c54"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.14.0\n","  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (18.1.1)\n","Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n","  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.12.2)\n","Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n","  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.64.1)\n","Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n","  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n","Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n","  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n","  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.44.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.4)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n","Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.16.0\n","    Uninstalling wrapt-1.16.0:\n","      Successfully uninstalled wrapt-1.16.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.1\n","    Uninstalling google-auth-oauthlib-1.2.1:\n","      Successfully uninstalled google-auth-oauthlib-1.2.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.0\n","    Uninstalling tensorboard-2.17.0:\n","      Successfully uninstalled tensorboard-2.17.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.0\n","    Uninstalling tensorflow-2.17.0:\n","      Successfully uninstalled tensorflow-2.17.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorstore 0.1.66 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\n","2.14.0\n"]}]},{"cell_type":"code","source":["# downloading the data\n","from zipfile import ZipFile\n","\n","!wget \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n","zip_ref = ZipFile(\"10_food_classes_10_percent.zip\")\n","zip_ref.extractall()\n","zip_ref.close()\n"],"metadata":{"id":"61KIl_MlCVXr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728318467250,"user_tz":-120,"elapsed":12907,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"09b76299-30d2-4cc5-ee79-d783a2064ce4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-07 16:27:34--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.207, 74.125.200.207, 74.125.130.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M  19.2MB/s    in 9.5s    \n","\n","2024-10-07 16:27:45 (16.9 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n","\n"]}]},{"cell_type":"code","source":["\n","# inspect our data !\n","from pathlib import Path\n","\n","data_dir = Path(\"10_food_classes_10_percent\")\n","for dirpath in data_dir.rglob('*'):\n","    if dirpath.is_dir():\n","        subdirs = [d for d in dirpath.iterdir() if d.is_dir()]\n","        files = [f for f in dirpath.iterdir() if f.is_file()]\n","        print(f\"There are {len(subdirs)} directories and {len(files)} images in '{dirpath}'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBGrfPe3cXCI","executionInfo":{"status":"ok","timestamp":1728318478243,"user_tz":-120,"elapsed":459,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"f764ca25-41d6-4c64-ef58-2bf69fd4ad01"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n"]}]},{"cell_type":"markdown","source":["### Creating data loaders (preparing the data)"],"metadata":{"id":"9wKxxY4ykmxr"}},{"cell_type":"code","source":["# setup data inputs\n","# since we have a nicely formated data folders we use the ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224,224)\n","BATCH_SIZE = 32\n","EPOCHS = 5\n","\n","train_dir = data_dir / \"train\"\n","test_dir = data_dir / \"test\"\n","\n","train_data_gen = ImageDataGenerator(rescale=1/255.)\n","test_data_gen = ImageDataGenerator(rescale=1/255.)\n","\n","train_data_10_percent = train_data_gen.flow_from_directory(train_dir,\n","                                                           target_size=IMAGE_SHAPE,\n","                                                           batch_size=BATCH_SIZE,\n","                                                           class_mode=\"categorical\")\n","\n","test_data_10_percent = test_data_gen.flow_from_directory(test_dir,\n","                                                         target_size=IMAGE_SHAPE,\n","                                                         batch_size=BATCH_SIZE,\n","                                                         class_mode=\"categorical\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQLw6ThGjgsf","executionInfo":{"status":"ok","timestamp":1728318488734,"user_tz":-120,"elapsed":429,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"13894044-6c52-48da-ce26-0ae746c8cae7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 750 images belonging to 10 classes.\n","Found 2500 images belonging to 10 classes.\n"]}]},{"cell_type":"markdown","source":["### Setting up callbacks (things to run whilst our model trains)\n","\n","Callbacks are extra functionality we can add to our models to be performed during or after training. Some of the most popular callbacks are:\n","\n","- Tracking experiments with the TensorBoard Callback\n","- Model checkpoint with the ModelCheckpoint callback\n","- stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"],"metadata":{"id":"zjlLuhpWmeKs"}},{"cell_type":"code","source":["# let's create a function to build a TensorBoard callback\n","from datetime import datetime\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","    print(f\"Saving TensorBoard log files to: {log_dir}\")\n","    return tensorboard_callback"],"metadata":{"id":"FpNvPIl8lnG0","executionInfo":{"status":"ok","timestamp":1728318495398,"user_tz":-120,"elapsed":716,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Creating models using TensorFlow Hub\n","\n","In the past we'have used TensorFlow to create our own models layer by layer from scratch\n","\n","Now we're going to do a similar process, except the majority of our model's layer will come from TensorFlow Hub\n","\n","https://www.tensorflow.org/hub?hl=fr\n","\n","Browsing the TensorFlow Hub page and sorting for image classification, we found the following feature vector model link:\n","https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n","\n"],"metadata":{"id":"vtircjqGMlAx"}},{"cell_type":"code","source":["# let's compare the following two models\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""],"metadata":{"id":"D5b1K4TKQVt2","executionInfo":{"status":"ok","timestamp":1728318498678,"user_tz":-120,"elapsed":1200,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# import dependencies\n","import tensorflow_hub as hub\n","import tensorflow as tf"],"metadata":{"id":"aOKHPE5rQXlq","executionInfo":{"status":"ok","timestamp":1728318501256,"user_tz":-120,"elapsed":5,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)\n","print(hub.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_6yXkDdTc3t","executionInfo":{"status":"ok","timestamp":1728318501256,"user_tz":-120,"elapsed":4,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"a185607e-d627-407d-a41a-01cfe30301ef"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2.14.0\n","0.16.1\n"]}]},{"cell_type":"code","source":["!pip show tensorflow-hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zfQf5x8UZjr","executionInfo":{"status":"ok","timestamp":1728318505116,"user_tz":-120,"elapsed":1979,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"d4c759a4-6e8a-4a17-b08b-144647aac17c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorflow-hub\n","Version: 0.16.1\n","Summary: TensorFlow Hub is a library to foster the publication, discovery, and consumption of reusable parts of machine learning models.\n","Home-page: https://github.com/tensorflow/hub\n","Author: Google LLC\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: numpy, protobuf, tf-keras\n","Required-by: \n"]}]},{"cell_type":"code","source":["#! pip install --upgrade keras"],"metadata":{"id":"lireFBkbKpSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n","import tensorflow_hub as hub\n","print(hub.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XesoSb80MV5S","executionInfo":{"status":"ok","timestamp":1728318507096,"user_tz":-120,"elapsed":2,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"6a1fc291-5f65-4d09-a86a-e3d3c40358e5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2.14.0\n","0.16.1\n"]}]},{"cell_type":"code","source":["import keras\n","print(keras.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avzq4BU7MWBh","executionInfo":{"status":"ok","timestamp":1728318507595,"user_tz":-120,"elapsed":2,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"33231af2-295f-4db5-ec23-354ae22b2b93"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2.14.0\n"]}]},{"cell_type":"code","source":["# Let's make a create_model() function to create a model from URL\n","def create_model(model_url, num_classes=10):\n","    \"\"\"\n","    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it\n","    Args:\n","      model_url (str): A TensorFlow Hub feature extraction URL\n","      num_classes (int): Number of output neurons in the output layer,\n","        should be equal to number of target classes, default 10\n","      Returns:\n","      An uncompiled Keras Sequential model with model_url as feature\n","      extractor layer and Dense outpu layer with num_classes outputs\n","    \"\"\"\n","\n","    print(f\"Building model with {model_url}\")\n","    feature_extraction_layer = hub.KerasLayer(model_url,trainable=False)\n","\n","    model=tf.keras.Sequential([\n","        tf.keras.Input(shape=(224,224,3)),\n","        feature_extraction_layer,\n","        tf.keras.layers.Dense(num_classes,activation='softmax')\n","    ])\n","    return model\n"],"metadata":{"id":"SclRjK9wPP6p","executionInfo":{"status":"ok","timestamp":1728318510520,"user_tz":-120,"elapsed":517,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Creating and testing ResNet TensorFlow Hub"],"metadata":{"id":"oPizvv7KSW4p"}},{"cell_type":"code","source":["eff_net = create_model(efficientnet_url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwbHxi7hSV-I","executionInfo":{"status":"ok","timestamp":1728318526065,"user_tz":-120,"elapsed":13594,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"19bc6645-6d89-431b-d8fd-1931e547664f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model with https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n"]}]},{"cell_type":"code","source":["res_net = create_model(resnet_url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bg4olQMISyfO","executionInfo":{"status":"ok","timestamp":1728318535363,"user_tz":-120,"elapsed":9301,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"5b84c2bd-8f08-4709-884b-0de26ec698be"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model with https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"aLtN_LC2mi8I"}},{"cell_type":"markdown","source":["### Compiling the models"],"metadata":{"id":"fVasBwoPmk1a"}},{"cell_type":"code","source":["# efficient net\n","eff_net.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","# resnet\n","res_net.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n"],"metadata":{"id":"ybJAQl7cQelX","executionInfo":{"status":"ok","timestamp":1728318535363,"user_tz":-120,"elapsed":3,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["### Evaluate the model"],"metadata":{"id":"KuRCx9itnGi3"}},{"cell_type":"code","source":["# efficient net\n","hisotry_eff_net = eff_net.fit(train_data_10_percent, epochs=5, validation_data=test_data_10_percent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvbRxQ7YnHwQ","executionInfo":{"status":"ok","timestamp":1728318650966,"user_tz":-120,"elapsed":111122,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"3a27663e-1f42-4d9a-bfe1-bb7ddb275e25"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","24/24 [==============================] - 30s 920ms/step - loss: 1.8581 - accuracy: 0.4240 - val_loss: 1.2778 - val_accuracy: 0.7248\n","Epoch 2/5\n","24/24 [==============================] - 20s 864ms/step - loss: 1.0714 - accuracy: 0.7720 - val_loss: 0.8625 - val_accuracy: 0.8192\n","Epoch 3/5\n","24/24 [==============================] - 20s 874ms/step - loss: 0.7671 - accuracy: 0.8373 - val_loss: 0.6982 - val_accuracy: 0.8392\n","Epoch 4/5\n","24/24 [==============================] - 20s 862ms/step - loss: 0.6184 - accuracy: 0.8680 - val_loss: 0.6093 - val_accuracy: 0.8540\n","Epoch 5/5\n","24/24 [==============================] - 20s 869ms/step - loss: 0.5215 - accuracy: 0.8813 - val_loss: 0.5590 - val_accuracy: 0.8588\n"]}]},{"cell_type":"code","source":["history_res_net = res_net.fit(train_data_10_percent, epochs=5, validation_data=test_data_10_percent,\n","                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", experiment_name=\"resenet50V2\")]\n","                              )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7ZMqrqsnaju","outputId":"76ca6dac-3d33-4965-c54c-284367de0ebd","executionInfo":{"status":"ok","timestamp":1728319816712,"user_tz":-120,"elapsed":241961,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: tensorflow_hub/resenet50V2/20241007-164614\n","Epoch 1/5\n","24/24 [==============================] - 51s 2s/step - loss: 1.9762 - accuracy: 0.3627 - val_loss: 1.2111 - val_accuracy: 0.6188\n","Epoch 2/5\n","24/24 [==============================] - 50s 2s/step - loss: 0.9181 - accuracy: 0.7347 - val_loss: 0.8438 - val_accuracy: 0.7344\n","Epoch 3/5\n","24/24 [==============================] - 47s 2s/step - loss: 0.6207 - accuracy: 0.8387 - val_loss: 0.7531 - val_accuracy: 0.7640\n","Epoch 4/5\n","24/24 [==============================] - 47s 2s/step - loss: 0.4844 - accuracy: 0.8760 - val_loss: 0.7166 - val_accuracy: 0.7632\n","Epoch 5/5\n","24/24 [==============================] - 47s 2s/step - loss: 0.3822 - accuracy: 0.9080 - val_loss: 0.6887 - val_accuracy: 0.7736\n"]}]},{"cell_type":"code","source":["# Let's create a function to plot our curves ....\n","# we could put a function like this into a script called helper.py and import it when we need it !\n","from matplotlib import pyplot as plt\n","\n","def plot_loss_curves(history):\n","    \"\"\"\n","    Returns separate loss curves for training and validation metrics\n","    Args:\n","      history: TensorFlow model History object\n","    \"\"\"\n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","\n","    accuracy = history.history[\"accuracy\"]\n","    val_accuracy = history.history[\"val_accuracy\"]\n","\n","    epochs=range(len(history.history[\"loss\"]))\n","\n","    #plot loss\n","    plt.plot(epochs, loss, label=\"training_loss\")\n","    plt.plot(epochs, val_loss, label=\"val_loss\")\n","    plt.title(\"loss\")\n","    plt.xalbel(\"Epochs\")\n","    plt.legend()\n","\n","    #plot accuracy\n","    plt.figure()\n","    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n","    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n","    plt.title(\"accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()"],"metadata":{"id":"jirAK-fsrDzG","executionInfo":{"status":"ok","timestamp":1728319825997,"user_tz":-120,"elapsed":1132,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## Comparing our models\n","\n","it is really tedious to compare model by scrolling up each time so the idea is to put callback (tensor board) when runing the models"],"metadata":{"id":"og99-be34Lzp"}},{"cell_type":"code","source":["# upload tensorboard\n","\n","!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","--name \"Resnet\" \\\n","--description \"Plotting our experiement\" \\\n","--one_shot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIlgGFiG4PBm","executionInfo":{"status":"ok","timestamp":1728320000197,"user_tz":-120,"elapsed":32337,"user":{"displayName":"maxime Collet","userId":"00430877086868619097"}},"outputId":"22549873-a4b9-41ae-bb9b-9e92ddacdf42"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-10-07 16:52:48.863624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-07 16:52:48.863673: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-07 16:52:48.863705: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-07 16:52:49.878837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-10-07 16:52:51.244367: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","\n","***** TensorBoard Uploader *****\n","\n","This will upload your TensorBoard logs to https://tensorboard.dev/ from\n","the following directory:\n","\n","./tensorflow_hub/\n","\n","This TensorBoard will be visible to everyone. Do not upload sensitive\n","data.\n","\n","Your use of this service is subject to Google's Terms of Service\n","<https://policies.google.com/terms> and Privacy Policy\n","<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n","<https://tensorboard.dev/policy/terms/>.\n","\n","This notice will not be shown again while you are logged into the uploader.\n","To log out, run `tensorboard dev auth revoke`.\n","\n","Continue? (yes/NO) yes\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n","    sys.exit(run_main())\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main.py\", line 46, in run_main\n","    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 276, in main\n","    return runner(self.flags) or 0\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 691, in run\n","    return _run(flags, self._experiment_url_callback)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 94, in _run\n","    credentials = auth.authenticate_user(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/auth.py\", line 243, in authenticate_user\n","    return flow.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/auth.py\", line 260, in run\n","    device_response = self._send_device_auth_request()\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/auth.py\", line 292, in _send_device_auth_request\n","    raise RuntimeError(\n","RuntimeError: There was an error while contacting Google's authorization server. Please try again later.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hW0ChP7f5dBs"},"execution_count":null,"outputs":[]}]}